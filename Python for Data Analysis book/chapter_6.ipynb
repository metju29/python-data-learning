{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.1 Reading and Writing Data in Text Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a   b   c   d message\n",
      "0  1   2   3   4   hello\n",
      "1  5   6   7   8   world\n",
      "2  9  10  11  12     foo\n",
      "\n",
      "\n",
      "   a   b   c   d message\n",
      "0  1   2   3   4   hello\n",
      "1  5   6   7   8   world\n",
      "2  9  10  11  12     foo\n",
      "\n",
      "\n",
      "   0   1   2   3      4\n",
      "0  1   2   3   4  hello\n",
      "1  5   6   7   8  world\n",
      "2  9  10  11  12    foo\n",
      "\n",
      "\n",
      "   a   b   c   d message\n",
      "0  1   2   3   4   hello\n",
      "1  5   6   7   8   world\n",
      "2  9  10  11  12     foo\n",
      "\n",
      "\n",
      "         a   b   c   d\n",
      "message               \n",
      "hello    1   2   3   4\n",
      "world    5   6   7   8\n",
      "foo      9  10  11  12\n",
      "\n",
      "\n",
      "           value1  value2\n",
      "key1 key2                \n",
      "one  a          1       2\n",
      "     b          3       4\n",
      "     c          5       6\n",
      "     d          7       8\n",
      "two  a          9      10\n",
      "     b         11      12\n",
      "     c         13      14\n",
      "     d         15      16\n",
      "\n",
      "\n",
      "['            A         B         C\\n', 'aaa -0.264438 -1.026059 -0.619500\\n', 'bbb  0.927272  0.302904 -0.032399\\n', 'ccc -0.264273 -0.386314 -0.217601\\n', 'ddd -0.871858 -0.348382  1.100491\\n']\n",
      "\n",
      "\n",
      "            A         B         C\n",
      "aaa -0.264438 -1.026059 -0.619500\n",
      "bbb  0.927272  0.302904 -0.032399\n",
      "ccc -0.264273 -0.386314 -0.217601\n",
      "ddd -0.871858 -0.348382  1.100491\n",
      "\n",
      "\n",
      "   a   b   c   d message\n",
      "0  1   2   3   4   hello\n",
      "1  5   6   7   8   world\n",
      "2  9  10  11  12     foo\n",
      "\n",
      "\n",
      "  something  a   b     c   d message\n",
      "0       one  1   2   3.0   4     NaN\n",
      "1       two  5   6   NaN   8   world\n",
      "2     three  9  10  11.0  12     foo\n",
      "\n",
      "\n",
      "   something      a      b      c      d  message\n",
      "0      False  False  False  False  False     True\n",
      "1      False  False  False   True  False    False\n",
      "2      False  False  False  False  False    False\n",
      "\n",
      "\n",
      "  something  a   b     c   d message\n",
      "0       one  1   2   3.0   4     NaN\n",
      "1       two  5   6   NaN   8   world\n",
      "2     three  9  10  11.0  12     foo\n",
      "\n",
      "\n",
      "  something  a   b     c   d message\n",
      "0       one  1   2   3.0   4     NaN\n",
      "1       NaN  5   6   NaN   8   world\n",
      "2     three  9  10  11.0  12     NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('samples/ex1.csv')\n",
    "print(df)\n",
    "print('\\n')\n",
    "print(pd.read_table('samples/ex1.csv', sep=','))\n",
    "print('\\n')\n",
    "print(pd.read_csv('samples/ex2.csv', header=None))\n",
    "print('\\n')\n",
    "print(pd.read_csv('samples/ex2.csv', names=['a', 'b', 'c', 'd', 'message']))\n",
    "\n",
    "names = ['a', 'b', 'c', 'd', 'message']\n",
    "print('\\n')\n",
    "print(pd.read_csv('samples/ex2.csv', names=names, index_col='message'))\n",
    "\n",
    "parsed = pd.read_csv('samples/csv_mindex.csv',\n",
    "                     index_col=['key1', 'key2'])\n",
    "print('\\n')\n",
    "print(parsed)\n",
    "\n",
    "print('\\n')\n",
    "print(list(open('samples/ex3.txt')))\n",
    "\n",
    "result = pd.read_table('samples/ex3.txt', sep='\\\\s+')\n",
    "print('\\n')\n",
    "print(result)\n",
    "\n",
    "print('\\n')\n",
    "print(pd.read_csv('samples/ex4.csv', skiprows=[0 ,2, 3]))\n",
    "\n",
    "result = pd.read_csv('samples/ex5.csv')\n",
    "print('\\n')\n",
    "print(result)\n",
    "print('\\n')\n",
    "print(pd.isnull(result))\n",
    "\n",
    "result = pd.read_csv('samples/ex5.csv', na_values=['NULL'])\n",
    "print('\\n')\n",
    "print(result)\n",
    "\n",
    "sentinels = {'message': ['foo', 'NA'], 'something': ['two']}\n",
    "print('\\n')\n",
    "print(pd.read_csv('samples/ex5.csv', na_values=sentinels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           one       two     three      four key\n",
      "0     0.467976 -0.038649 -0.295344 -1.824726   L\n",
      "1    -0.358893  1.404453  0.704965 -0.200638   B\n",
      "2    -0.501840  0.659254 -0.421691 -0.057688   G\n",
      "3     0.204886  1.074134  1.388361 -0.982404   R\n",
      "4     0.354628 -0.133116  0.283763 -0.837063   Q\n",
      "...        ...       ...       ...       ...  ..\n",
      "9995  2.311896 -0.417070 -1.409599 -0.515821   L\n",
      "9996 -0.479893 -0.650419  0.745152 -0.646038   E\n",
      "9997  0.523331  0.787112  0.486066  1.093156   K\n",
      "9998 -0.362559  0.598894 -1.843201  0.887292   G\n",
      "9999 -0.096376 -1.012999 -0.657431 -0.573315   0\n",
      "\n",
      "[10000 rows x 5 columns]\n",
      "\n",
      "\n",
      "        one       two     three      four key\n",
      "0  0.467976 -0.038649 -0.295344 -1.824726   L\n",
      "1 -0.358893  1.404453  0.704965 -0.200638   B\n",
      "2 -0.501840  0.659254 -0.421691 -0.057688   G\n",
      "3  0.204886  1.074134  1.388361 -0.982404   R\n",
      "4  0.354628 -0.133116  0.283763 -0.837063   Q\n",
      "\n",
      "\n",
      "<pandas.io.parsers.readers.TextFileReader object at 0x107997f70>\n",
      "\n",
      "\n",
      "key\n",
      "0    151\n",
      "1    146\n",
      "2    152\n",
      "3    162\n",
      "4    171\n",
      "5    157\n",
      "6    166\n",
      "7    164\n",
      "8    162\n",
      "9    150\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Reading Text Files in Pieces\n",
    "\n",
    "pd.options.display.max_rows = 10\n",
    "\n",
    "result = pd.read_csv('samples/ex6.csv')\n",
    "print(result)\n",
    "print('\\n')\n",
    "print(pd.read_csv('samples/ex6.csv', nrows=5))\n",
    "\n",
    "chunker = pd.read_csv('samples/ex6.csv', chunksize=1000)\n",
    "print('\\n')\n",
    "print(chunker)\n",
    "\n",
    "tot = pd.Series([])\n",
    "for piece in chunker:\n",
    "    tot = tot.add(piece['key'].value_counts(), fill_value=0)\n",
    "\n",
    "tot.sort_values(ascending=False)\n",
    "print('\\n')\n",
    "print(tot[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  something  a   b     c   d message\n",
      "0       one  1   2   3.0   4     NaN\n",
      "1       two  5   6   NaN   8   world\n",
      "2     three  9  10  11.0  12     foo\n",
      "\n",
      "\n",
      "|something|a|b|c|d|message\n",
      "0|one|1|2|3.0|4|\n",
      "1|two|5|6||8|world\n",
      "2|three|9|10|11.0|12|foo\n",
      "\n",
      "\n",
      ",something,a,b,c,d,message\n",
      "0,one,1,2,3.0,4,NULL\n",
      "1,two,5,6,NULL,8,world\n",
      "2,three,9,10,11.0,12,foo\n",
      "None\n",
      "\n",
      "\n",
      "one,1,2,3.0,4,\n",
      "two,5,6,,8,world\n",
      "three,9,10,11.0,12,foo\n",
      "None\n",
      "\n",
      "\n",
      "a,b,c\n",
      "1,2,3.0\n",
      "5,6,\n",
      "9,10,11.0\n",
      "None\n",
      "\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Writing Data to Text Format\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "data = pd.read_csv('examples/ex5.csv')\n",
    "print(data)\n",
    "\n",
    "data.to_csv('examples/out.csv')\n",
    "\n",
    "print('\\n')\n",
    "data.to_csv(sys.stdout, sep='|')\n",
    "\n",
    "print('\\n')\n",
    "print(data.to_csv(sys.stdout, na_rep='NULL'))\n",
    "\n",
    "print('\\n')\n",
    "print(data.to_csv(sys.stdout, index=False, header=False))\n",
    "\n",
    "print('\\n')\n",
    "print(data.to_csv(sys.stdout, index=False, columns=['a','b', 'c']))\n",
    "\n",
    "dates = pd.date_range('1/1/2000', periods=7)\n",
    "ts = pd.Series(np.arange(7), index=dates)\n",
    "print('\\n')\n",
    "print(ts.to_csv('examples/tseries.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c']\n",
      "['1', '2', '3']\n",
      "['1', '2', '3']\n",
      "\n",
      "\n",
      "{'a': ('1', '1'), 'b': ('2', '2'), 'c': ('3', '3')}\n"
     ]
    }
   ],
   "source": [
    "# Working with Delimited Formats\n",
    "\n",
    "import csv\n",
    "\n",
    "\n",
    "f = open('examples/ex7.csv')\n",
    "reader = csv.reader(f)\n",
    "\n",
    "for line in reader:\n",
    "    print(line)\n",
    "\n",
    "with open('examples/ex7.csv') as f:\n",
    "    lines = list(csv.reader(f))\n",
    "\n",
    "header, values = lines[0], lines[1:]\n",
    "data_dict = {h: v for h, v in zip(header, zip(*values))}\n",
    "print('\\n')\n",
    "print(data_dict)\n",
    "\n",
    "class my_dialect(csv.Dialect):\n",
    "    lineterminator = '\\n'\n",
    "    delimiter = ';'\n",
    "    quotachar = '\"'\n",
    "    quoting = csv.QUOTE_MINIMAL\n",
    "\n",
    "reader = csv.reader(f, dialect=my_dialect)\n",
    "\n",
    "reader = csv.reader(f, delimiter='|')\n",
    "\n",
    "with open('mydata.csv', 'w') as f:\n",
    "    writer = csv.writer(f, dialect=my_dialect)\n",
    "    writer.writerow(('one', 'two', 'three'))\n",
    "    writer.writerow(('1', '2', '3'))\n",
    "    writer.writerow(('4', '5', '6'))\n",
    "    writer.writerow(('7', '8', '9'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Wes', 'cities_lived': ['Akron', 'Nashville', 'New York', 'San Francisco'], 'pet': None, 'siblings': [{'name': 'Scott', 'age': 34, 'hobbies': ['guitars', 'soccer']}, {'name': 'Katie', 'age': 42, 'hobbies': ['diving', 'art']}]}\n",
      "\n",
      "\n",
      "    name  age\n",
      "0  Scott   34\n",
      "1  Katie   42\n",
      "\n",
      "\n",
      "   a  b  c\n",
      "0  1  2  3\n",
      "1  4  5  6\n",
      "2  7  8  9\n",
      "\n",
      "\n",
      "{\"a\":{\"0\":1,\"1\":4,\"2\":7},\"b\":{\"0\":2,\"1\":5,\"2\":8},\"c\":{\"0\":3,\"1\":6,\"2\":9}}\n",
      "[{\"a\":1,\"b\":2,\"c\":3},{\"a\":4,\"b\":5,\"c\":6},{\"a\":7,\"b\":8,\"c\":9}]\n"
     ]
    }
   ],
   "source": [
    "# JSON Data\n",
    "\n",
    "import json\n",
    "\n",
    "obj = \"\"\"\n",
    "{\"name\": \"Wes\",\n",
    " \"cities_lived\": [\"Akron\", \"Nashville\", \"New York\", \"San Francisco\"],\n",
    " \"pet\": null,\n",
    " \"siblings\": [{\"name\": \"Scott\", \"age\": 34, \"hobbies\": [\"guitars\", \"soccer\"]},\n",
    "              {\"name\": \"Katie\", \"age\": 42, \"hobbies\": [\"diving\", \"art\"]}]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "result = json.loads(obj)\n",
    "print(result)\n",
    "\n",
    "asjson = json.dumps(result)\n",
    "\n",
    "siblings = pd.DataFrame(result['siblings'], columns=['name', 'age'])\n",
    "print('\\n')\n",
    "print(siblings)\n",
    "\n",
    "data = pd.read_json('examples/example.json')\n",
    "print('\\n')\n",
    "print(data)\n",
    "\n",
    "print('\\n')\n",
    "print(data.to_json())\n",
    "print(data.to_json(orient='records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n",
      "\n",
      "                      Bank Name             City  ST   CERT  \\\n",
      "0                   Allied Bank         Mulberry  AR     91   \n",
      "1  The Woodbury Banking Company         Woodbury  GA  11297   \n",
      "2        First CornerStone Bank  King of Prussia  PA  35312   \n",
      "3            Trust Company Bank          Memphis  TN   9956   \n",
      "4    North Milwaukee State Bank        Milwaukee  WI  20364   \n",
      "\n",
      "                 Acquiring Institution        Closing Date       Updated Date  \n",
      "0                         Today's Bank  September 23, 2016  November 17, 2016  \n",
      "1                          United Bank     August 19, 2016  November 17, 2016  \n",
      "2  First-Citizens Bank & Trust Company         May 6, 2016  September 6, 2016  \n",
      "3           The Bank of Fayette County      April 29, 2016  September 6, 2016  \n",
      "4  First-Citizens Bank & Trust Company      March 11, 2016      June 16, 2016  \n",
      "\n",
      "\n",
      "Closing Date\n",
      "2010    157\n",
      "2009    140\n",
      "2011     92\n",
      "2012     51\n",
      "2008     25\n",
      "       ... \n",
      "2004      4\n",
      "2001      4\n",
      "2007      3\n",
      "2003      3\n",
      "2000      2\n",
      "Name: count, Length: 15, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# XML and HTML: Web Scraping\n",
    "\n",
    "tables = pd.read_html('examples/fdic_failed_bank_list.html')\n",
    "print(len(tables))\n",
    "\n",
    "failures = tables[0]\n",
    "print('\\n')\n",
    "print(failures.head())\n",
    "\n",
    "close_timestamps = pd.to_datetime(failures['Closing Date'])\n",
    "print('\\n')\n",
    "print(close_timestamps.dt.year.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "            AGENCY_NAME                        INDICATOR_NAME  \\\n",
      "0  Metro-North Railroad  On-Time Performance (West of Hudson)   \n",
      "1  Metro-North Railroad  On-Time Performance (West of Hudson)   \n",
      "2  Metro-North Railroad  On-Time Performance (West of Hudson)   \n",
      "3  Metro-North Railroad  On-Time Performance (West of Hudson)   \n",
      "4  Metro-North Railroad  On-Time Performance (West of Hudson)   \n",
      "\n",
      "                                         DESCRIPTION  PERIOD_YEAR  \\\n",
      "0  Percent of commuter trains that arrive at thei...         2008   \n",
      "1  Percent of commuter trains that arrive at thei...         2008   \n",
      "2  Percent of commuter trains that arrive at thei...         2008   \n",
      "3  Percent of commuter trains that arrive at thei...         2008   \n",
      "4  Percent of commuter trains that arrive at thei...         2008   \n",
      "\n",
      "   PERIOD_MONTH            CATEGORY FREQUENCY INDICATOR_UNIT YTD_TARGET  \\\n",
      "0             1  Service Indicators         M              %       95.0   \n",
      "1             2  Service Indicators         M              %       95.0   \n",
      "2             3  Service Indicators         M              %       95.0   \n",
      "3             4  Service Indicators         M              %       95.0   \n",
      "4             5  Service Indicators         M              %       95.0   \n",
      "\n",
      "  YTD_ACTUAL MONTHLY_TARGET MONTHLY_ACTUAL  \n",
      "0       96.9           95.0           96.9  \n",
      "1       96.0           95.0           95.0  \n",
      "2       96.3           95.0           96.9  \n",
      "3       96.8           95.0           98.3  \n",
      "4       96.6           95.0           95.8  \n",
      "\n",
      "\n",
      "Google\n",
      "\n",
      "\n",
      "html://www.google.com\n",
      "\n",
      "\n",
      "Google\n"
     ]
    }
   ],
   "source": [
    "# XML\n",
    "\n",
    "from lxml import objectify\n",
    "from io import StringIO\n",
    "\n",
    "path = 'data/mta_perf/Performance_MNR.xml'\n",
    "parsed = objectify.parse(open(path))\n",
    "root = parsed.getroot()\n",
    "\n",
    "data = []\n",
    "\n",
    "skip_fields = ['PARENT_SEQ', 'INDICATOR_SEQ', 'DESIRED_CHANGE', 'DECIMAL_PLACES']\n",
    "\n",
    "for elt in root.INDICATOR:\n",
    "    el_data = {}\n",
    "    for child in elt.getchildren():\n",
    "        if child.tag in skip_fields:\n",
    "            continue\n",
    "        el_data[child.tag] = child.pyval\n",
    "    data.append(el_data)\n",
    "\n",
    "perf = pd.DataFrame(data)\n",
    "print('\\n')\n",
    "print(perf.head())\n",
    "\n",
    "tag = '<a href=\"html://www.google.com\">Google</a>'\n",
    "root = objectify.parse(StringIO(tag)).getroot()\n",
    "print('\\n')\n",
    "print(root)\n",
    "print('\\n')\n",
    "print(root.get('href'))\n",
    "print('\\n')\n",
    "print(root.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
