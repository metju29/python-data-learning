{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.1 Reading and Writing Data in Text Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a   b   c   d message\n",
      "0  1   2   3   4   hello\n",
      "1  5   6   7   8   world\n",
      "2  9  10  11  12     foo\n",
      "\n",
      "\n",
      "   a   b   c   d message\n",
      "0  1   2   3   4   hello\n",
      "1  5   6   7   8   world\n",
      "2  9  10  11  12     foo\n",
      "\n",
      "\n",
      "   0   1   2   3      4\n",
      "0  1   2   3   4  hello\n",
      "1  5   6   7   8  world\n",
      "2  9  10  11  12    foo\n",
      "\n",
      "\n",
      "   a   b   c   d message\n",
      "0  1   2   3   4   hello\n",
      "1  5   6   7   8   world\n",
      "2  9  10  11  12     foo\n",
      "\n",
      "\n",
      "         a   b   c   d\n",
      "message               \n",
      "hello    1   2   3   4\n",
      "world    5   6   7   8\n",
      "foo      9  10  11  12\n",
      "\n",
      "\n",
      "           value1  value2\n",
      "key1 key2                \n",
      "one  a          1       2\n",
      "     b          3       4\n",
      "     c          5       6\n",
      "     d          7       8\n",
      "two  a          9      10\n",
      "     b         11      12\n",
      "     c         13      14\n",
      "     d         15      16\n",
      "\n",
      "\n",
      "['            A         B         C\\n', 'aaa -0.264438 -1.026059 -0.619500\\n', 'bbb  0.927272  0.302904 -0.032399\\n', 'ccc -0.264273 -0.386314 -0.217601\\n', 'ddd -0.871858 -0.348382  1.100491\\n']\n",
      "\n",
      "\n",
      "            A         B         C\n",
      "aaa -0.264438 -1.026059 -0.619500\n",
      "bbb  0.927272  0.302904 -0.032399\n",
      "ccc -0.264273 -0.386314 -0.217601\n",
      "ddd -0.871858 -0.348382  1.100491\n",
      "\n",
      "\n",
      "   a   b   c   d message\n",
      "0  1   2   3   4   hello\n",
      "1  5   6   7   8   world\n",
      "2  9  10  11  12     foo\n",
      "\n",
      "\n",
      "  something  a   b     c   d message\n",
      "0       one  1   2   3.0   4     NaN\n",
      "1       two  5   6   NaN   8   world\n",
      "2     three  9  10  11.0  12     foo\n",
      "\n",
      "\n",
      "   something      a      b      c      d  message\n",
      "0      False  False  False  False  False     True\n",
      "1      False  False  False   True  False    False\n",
      "2      False  False  False  False  False    False\n",
      "\n",
      "\n",
      "  something  a   b     c   d message\n",
      "0       one  1   2   3.0   4     NaN\n",
      "1       two  5   6   NaN   8   world\n",
      "2     three  9  10  11.0  12     foo\n",
      "\n",
      "\n",
      "  something  a   b     c   d message\n",
      "0       one  1   2   3.0   4     NaN\n",
      "1       NaN  5   6   NaN   8   world\n",
      "2     three  9  10  11.0  12     NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('samples/ex1.csv')\n",
    "print(df)\n",
    "print('\\n')\n",
    "print(pd.read_table('samples/ex1.csv', sep=','))\n",
    "print('\\n')\n",
    "print(pd.read_csv('samples/ex2.csv', header=None))\n",
    "print('\\n')\n",
    "print(pd.read_csv('samples/ex2.csv', names=['a', 'b', 'c', 'd', 'message']))\n",
    "\n",
    "names = ['a', 'b', 'c', 'd', 'message']\n",
    "print('\\n')\n",
    "print(pd.read_csv('samples/ex2.csv', names=names, index_col='message'))\n",
    "\n",
    "parsed = pd.read_csv('samples/csv_mindex.csv',\n",
    "                     index_col=['key1', 'key2'])\n",
    "print('\\n')\n",
    "print(parsed)\n",
    "\n",
    "print('\\n')\n",
    "print(list(open('samples/ex3.txt')))\n",
    "\n",
    "result = pd.read_table('samples/ex3.txt', sep='\\\\s+')\n",
    "print('\\n')\n",
    "print(result)\n",
    "\n",
    "print('\\n')\n",
    "print(pd.read_csv('samples/ex4.csv', skiprows=[0 ,2, 3]))\n",
    "\n",
    "result = pd.read_csv('samples/ex5.csv')\n",
    "print('\\n')\n",
    "print(result)\n",
    "print('\\n')\n",
    "print(pd.isnull(result))\n",
    "\n",
    "result = pd.read_csv('samples/ex5.csv', na_values=['NULL'])\n",
    "print('\\n')\n",
    "print(result)\n",
    "\n",
    "sentinels = {'message': ['foo', 'NA'], 'something': ['two']}\n",
    "print('\\n')\n",
    "print(pd.read_csv('samples/ex5.csv', na_values=sentinels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           one       two     three      four key\n",
      "0     0.467976 -0.038649 -0.295344 -1.824726   L\n",
      "1    -0.358893  1.404453  0.704965 -0.200638   B\n",
      "2    -0.501840  0.659254 -0.421691 -0.057688   G\n",
      "3     0.204886  1.074134  1.388361 -0.982404   R\n",
      "4     0.354628 -0.133116  0.283763 -0.837063   Q\n",
      "...        ...       ...       ...       ...  ..\n",
      "9995  2.311896 -0.417070 -1.409599 -0.515821   L\n",
      "9996 -0.479893 -0.650419  0.745152 -0.646038   E\n",
      "9997  0.523331  0.787112  0.486066  1.093156   K\n",
      "9998 -0.362559  0.598894 -1.843201  0.887292   G\n",
      "9999 -0.096376 -1.012999 -0.657431 -0.573315   0\n",
      "\n",
      "[10000 rows x 5 columns]\n",
      "\n",
      "\n",
      "        one       two     three      four key\n",
      "0  0.467976 -0.038649 -0.295344 -1.824726   L\n",
      "1 -0.358893  1.404453  0.704965 -0.200638   B\n",
      "2 -0.501840  0.659254 -0.421691 -0.057688   G\n",
      "3  0.204886  1.074134  1.388361 -0.982404   R\n",
      "4  0.354628 -0.133116  0.283763 -0.837063   Q\n",
      "\n",
      "\n",
      "<pandas.io.parsers.readers.TextFileReader object at 0x107997f70>\n",
      "\n",
      "\n",
      "key\n",
      "0    151\n",
      "1    146\n",
      "2    152\n",
      "3    162\n",
      "4    171\n",
      "5    157\n",
      "6    166\n",
      "7    164\n",
      "8    162\n",
      "9    150\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Reading Text Files in Pieces\n",
    "\n",
    "pd.options.display.max_rows = 10\n",
    "\n",
    "result = pd.read_csv('samples/ex6.csv')\n",
    "print(result)\n",
    "print('\\n')\n",
    "print(pd.read_csv('samples/ex6.csv', nrows=5))\n",
    "\n",
    "chunker = pd.read_csv('samples/ex6.csv', chunksize=1000)\n",
    "print('\\n')\n",
    "print(chunker)\n",
    "\n",
    "tot = pd.Series([])\n",
    "for piece in chunker:\n",
    "    tot = tot.add(piece['key'].value_counts(), fill_value=0)\n",
    "\n",
    "tot.sort_values(ascending=False)\n",
    "print('\\n')\n",
    "print(tot[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  something  a   b     c   d message\n",
      "0       one  1   2   3.0   4     NaN\n",
      "1       two  5   6   NaN   8   world\n",
      "2     three  9  10  11.0  12     foo\n",
      "\n",
      "\n",
      "|something|a|b|c|d|message\n",
      "0|one|1|2|3.0|4|\n",
      "1|two|5|6||8|world\n",
      "2|three|9|10|11.0|12|foo\n",
      "\n",
      "\n",
      ",something,a,b,c,d,message\n",
      "0,one,1,2,3.0,4,NULL\n",
      "1,two,5,6,NULL,8,world\n",
      "2,three,9,10,11.0,12,foo\n",
      "None\n",
      "\n",
      "\n",
      "one,1,2,3.0,4,\n",
      "two,5,6,,8,world\n",
      "three,9,10,11.0,12,foo\n",
      "None\n",
      "\n",
      "\n",
      "a,b,c\n",
      "1,2,3.0\n",
      "5,6,\n",
      "9,10,11.0\n",
      "None\n",
      "\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Writing Data to Text Format\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "data = pd.read_csv('examples/ex5.csv')\n",
    "print(data)\n",
    "\n",
    "data.to_csv('examples/out.csv')\n",
    "\n",
    "print('\\n')\n",
    "data.to_csv(sys.stdout, sep='|')\n",
    "\n",
    "print('\\n')\n",
    "print(data.to_csv(sys.stdout, na_rep='NULL'))\n",
    "\n",
    "print('\\n')\n",
    "print(data.to_csv(sys.stdout, index=False, header=False))\n",
    "\n",
    "print('\\n')\n",
    "print(data.to_csv(sys.stdout, index=False, columns=['a','b', 'c']))\n",
    "\n",
    "dates = pd.date_range('1/1/2000', periods=7)\n",
    "ts = pd.Series(np.arange(7), index=dates)\n",
    "print('\\n')\n",
    "print(ts.to_csv('examples/tseries.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c']\n",
      "['1', '2', '3']\n",
      "['1', '2', '3']\n",
      "\n",
      "\n",
      "{'a': ('1', '1'), 'b': ('2', '2'), 'c': ('3', '3')}\n"
     ]
    }
   ],
   "source": [
    "# Working with Delimited Formats\n",
    "\n",
    "import csv\n",
    "\n",
    "\n",
    "f = open('examples/ex7.csv')\n",
    "reader = csv.reader(f)\n",
    "\n",
    "for line in reader:\n",
    "    print(line)\n",
    "\n",
    "with open('examples/ex7.csv') as f:\n",
    "    lines = list(csv.reader(f))\n",
    "\n",
    "header, values = lines[0], lines[1:]\n",
    "data_dict = {h: v for h, v in zip(header, zip(*values))}\n",
    "print('\\n')\n",
    "print(data_dict)\n",
    "\n",
    "class my_dialect(csv.Dialect):\n",
    "    lineterminator = '\\n'\n",
    "    delimiter = ';'\n",
    "    quotachar = '\"'\n",
    "    quoting = csv.QUOTE_MINIMAL\n",
    "\n",
    "reader = csv.reader(f, dialect=my_dialect)\n",
    "\n",
    "reader = csv.reader(f, delimiter='|')\n",
    "\n",
    "with open('mydata.csv', 'w') as f:\n",
    "    writer = csv.writer(f, dialect=my_dialect)\n",
    "    writer.writerow(('one', 'two', 'three'))\n",
    "    writer.writerow(('1', '2', '3'))\n",
    "    writer.writerow(('4', '5', '6'))\n",
    "    writer.writerow(('7', '8', '9'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Wes', 'cities_lived': ['Akron', 'Nashville', 'New York', 'San Francisco'], 'pet': None, 'siblings': [{'name': 'Scott', 'age': 34, 'hobbies': ['guitars', 'soccer']}, {'name': 'Katie', 'age': 42, 'hobbies': ['diving', 'art']}]}\n",
      "\n",
      "\n",
      "    name  age\n",
      "0  Scott   34\n",
      "1  Katie   42\n",
      "\n",
      "\n",
      "   a  b  c\n",
      "0  1  2  3\n",
      "1  4  5  6\n",
      "2  7  8  9\n",
      "\n",
      "\n",
      "{\"a\":{\"0\":1,\"1\":4,\"2\":7},\"b\":{\"0\":2,\"1\":5,\"2\":8},\"c\":{\"0\":3,\"1\":6,\"2\":9}}\n",
      "[{\"a\":1,\"b\":2,\"c\":3},{\"a\":4,\"b\":5,\"c\":6},{\"a\":7,\"b\":8,\"c\":9}]\n"
     ]
    }
   ],
   "source": [
    "# JSON Data\n",
    "\n",
    "import json\n",
    "\n",
    "obj = \"\"\"\n",
    "{\"name\": \"Wes\",\n",
    " \"cities_lived\": [\"Akron\", \"Nashville\", \"New York\", \"San Francisco\"],\n",
    " \"pet\": null,\n",
    " \"siblings\": [{\"name\": \"Scott\", \"age\": 34, \"hobbies\": [\"guitars\", \"soccer\"]},\n",
    "              {\"name\": \"Katie\", \"age\": 42, \"hobbies\": [\"diving\", \"art\"]}]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "result = json.loads(obj)\n",
    "print(result)\n",
    "\n",
    "asjson = json.dumps(result)\n",
    "\n",
    "siblings = pd.DataFrame(result['siblings'], columns=['name', 'age'])\n",
    "print('\\n')\n",
    "print(siblings)\n",
    "\n",
    "data = pd.read_json('examples/example.json')\n",
    "print('\\n')\n",
    "print(data)\n",
    "\n",
    "print('\\n')\n",
    "print(data.to_json())\n",
    "print(data.to_json(orient='records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n",
      "\n",
      "                      Bank Name             City  ST   CERT  \\\n",
      "0                   Allied Bank         Mulberry  AR     91   \n",
      "1  The Woodbury Banking Company         Woodbury  GA  11297   \n",
      "2        First CornerStone Bank  King of Prussia  PA  35312   \n",
      "3            Trust Company Bank          Memphis  TN   9956   \n",
      "4    North Milwaukee State Bank        Milwaukee  WI  20364   \n",
      "\n",
      "                 Acquiring Institution        Closing Date       Updated Date  \n",
      "0                         Today's Bank  September 23, 2016  November 17, 2016  \n",
      "1                          United Bank     August 19, 2016  November 17, 2016  \n",
      "2  First-Citizens Bank & Trust Company         May 6, 2016  September 6, 2016  \n",
      "3           The Bank of Fayette County      April 29, 2016  September 6, 2016  \n",
      "4  First-Citizens Bank & Trust Company      March 11, 2016      June 16, 2016  \n",
      "\n",
      "\n",
      "Closing Date\n",
      "2010    157\n",
      "2009    140\n",
      "2011     92\n",
      "2012     51\n",
      "2008     25\n",
      "       ... \n",
      "2004      4\n",
      "2001      4\n",
      "2007      3\n",
      "2003      3\n",
      "2000      2\n",
      "Name: count, Length: 15, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# XML and HTML: Web Scraping\n",
    "\n",
    "tables = pd.read_html('examples/fdic_failed_bank_list.html')\n",
    "print(len(tables))\n",
    "\n",
    "failures = tables[0]\n",
    "print('\\n')\n",
    "print(failures.head())\n",
    "\n",
    "close_timestamps = pd.to_datetime(failures['Closing Date'])\n",
    "print('\\n')\n",
    "print(close_timestamps.dt.year.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "            AGENCY_NAME                        INDICATOR_NAME  \\\n",
      "0  Metro-North Railroad  On-Time Performance (West of Hudson)   \n",
      "1  Metro-North Railroad  On-Time Performance (West of Hudson)   \n",
      "2  Metro-North Railroad  On-Time Performance (West of Hudson)   \n",
      "3  Metro-North Railroad  On-Time Performance (West of Hudson)   \n",
      "4  Metro-North Railroad  On-Time Performance (West of Hudson)   \n",
      "\n",
      "                                         DESCRIPTION  PERIOD_YEAR  \\\n",
      "0  Percent of commuter trains that arrive at thei...         2008   \n",
      "1  Percent of commuter trains that arrive at thei...         2008   \n",
      "2  Percent of commuter trains that arrive at thei...         2008   \n",
      "3  Percent of commuter trains that arrive at thei...         2008   \n",
      "4  Percent of commuter trains that arrive at thei...         2008   \n",
      "\n",
      "   PERIOD_MONTH            CATEGORY FREQUENCY INDICATOR_UNIT YTD_TARGET  \\\n",
      "0             1  Service Indicators         M              %       95.0   \n",
      "1             2  Service Indicators         M              %       95.0   \n",
      "2             3  Service Indicators         M              %       95.0   \n",
      "3             4  Service Indicators         M              %       95.0   \n",
      "4             5  Service Indicators         M              %       95.0   \n",
      "\n",
      "  YTD_ACTUAL MONTHLY_TARGET MONTHLY_ACTUAL  \n",
      "0       96.9           95.0           96.9  \n",
      "1       96.0           95.0           95.0  \n",
      "2       96.3           95.0           96.9  \n",
      "3       96.8           95.0           98.3  \n",
      "4       96.6           95.0           95.8  \n",
      "\n",
      "\n",
      "Google\n",
      "\n",
      "\n",
      "html://www.google.com\n",
      "\n",
      "\n",
      "Google\n"
     ]
    }
   ],
   "source": [
    "# XML\n",
    "\n",
    "from lxml import objectify\n",
    "from io import StringIO\n",
    "\n",
    "path = 'data/mta_perf/Performance_MNR.xml'\n",
    "parsed = objectify.parse(open(path))\n",
    "root = parsed.getroot()\n",
    "\n",
    "data = []\n",
    "\n",
    "skip_fields = ['PARENT_SEQ', 'INDICATOR_SEQ', 'DESIRED_CHANGE', 'DECIMAL_PLACES']\n",
    "\n",
    "for elt in root.INDICATOR:\n",
    "    el_data = {}\n",
    "    for child in elt.getchildren():\n",
    "        if child.tag in skip_fields:\n",
    "            continue\n",
    "        el_data[child.tag] = child.pyval\n",
    "    data.append(el_data)\n",
    "\n",
    "perf = pd.DataFrame(data)\n",
    "print('\\n')\n",
    "print(perf.head())\n",
    "\n",
    "tag = '<a href=\"html://www.google.com\">Google</a>'\n",
    "root = objectify.parse(StringIO(tag)).getroot()\n",
    "print('\\n')\n",
    "print(root)\n",
    "print('\\n')\n",
    "print(root.get('href'))\n",
    "print('\\n')\n",
    "print(root.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.2 Binary Data Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a   b   c   d message\n",
      "0  1   2   3   4   hello\n",
      "1  5   6   7   8   world\n",
      "2  9  10  11  12     foo\n",
      "\n",
      "\n",
      "   a   b   c   d message\n",
      "0  1   2   3   4   hello\n",
      "1  5   6   7   8   world\n",
      "2  9  10  11  12     foo\n"
     ]
    }
   ],
   "source": [
    "frame = pd.read_csv('examples/ex1.csv')\n",
    "\n",
    "print(frame)\n",
    "\n",
    "frame.to_pickle('examples/frame_pickle')\n",
    "\n",
    "print('\\n')\n",
    "print(pd.read_pickle('examples/frame_pickle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.io.pytables.HDFStore'>\n",
      "File path: mydata.h5\n",
      "\n",
      "\n",
      "\n",
      "           a\n",
      "0  -0.543987\n",
      "1   0.213193\n",
      "2  -0.462793\n",
      "3   1.154416\n",
      "4  -1.145929\n",
      "..       ...\n",
      "95  1.382085\n",
      "96  0.150979\n",
      "97 -1.457342\n",
      "98 -1.004296\n",
      "99  0.507004\n",
      "\n",
      "[100 rows x 1 columns]\n",
      "\n",
      "\n",
      "None\n",
      "           a\n",
      "10  0.267801\n",
      "11 -1.285871\n",
      "12  0.352943\n",
      "13 -1.232307\n",
      "14  1.139008\n",
      "15  0.368525\n"
     ]
    }
   ],
   "source": [
    "# Using HDF5 Format\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "frame = pd.DataFrame({'a': np.random.randn(100)})\n",
    "store = pd.HDFStore('mydata.h5')\n",
    "store['obj1'] = frame\n",
    "store['obj1_col'] = frame['a']\n",
    "\n",
    "print(store)\n",
    "\n",
    "print('\\n')\n",
    "print(store['obj1'])\n",
    "\n",
    "print('\\n')\n",
    "print(store.put('obj2', frame, format='table'))\n",
    "print(store.select('obj2', where=['index >= 10 and index <= 15']))\n",
    "store.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  a   b   c   d message\n",
      "0           0  1   2   3   4   hello\n",
      "1           1  5   6   7   8   world\n",
      "2           2  9  10  11  12     foo\n",
      "\n",
      "\n",
      "   Unnamed: 0  a   b   c   d message\n",
      "0           0  1   2   3   4   hello\n",
      "1           1  5   6   7   8   world\n",
      "2           2  9  10  11  12     foo\n"
     ]
    }
   ],
   "source": [
    "# Reading Microsoft Excel Files\n",
    "xlsx = pd.ExcelFile('examples/ex1.xlsx')\n",
    "print(pd.read_excel(xlsx, 'Sheet1'))\n",
    "\n",
    "frame = pd.read_excel('examples/ex1.xlsx', 'Sheet1')\n",
    "print('\\n')\n",
    "print(frame)\n",
    "\n",
    "writer = pd.ExcelWriter('examples/ex2.xlsx')\n",
    "frame.to_excel(excel_writer=writer, sheet_name='Sheet1')\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.3 Interacting with Web APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "\n",
      "\n",
      "Incorrect rolling std() results on very large DataFrames\n",
      "\n",
      "\n",
      "    number                                              title  \\\n",
      "0    61677  Incorrect rolling std() results on very large ...   \n",
      "1    61676    BUG: Implicit conversion to float64 with isin()   \n",
      "2    61675  BUG: DataFrame.join(other) raises InvalidIndex...   \n",
      "3    61674      BUG: fix: `list` as index item does not raise   \n",
      "4    61673  DOC: Document two-issue limit for `take` comma...   \n",
      "5    61671  BUG: np.nan to datetime assertionerror when to...   \n",
      "6    61670  CLN: Use dedup_names for column name mangling ...   \n",
      "7    61669  ENH: Switch to trusted publishing for package ...   \n",
      "8    61668        Bump pypa/cibuildwheel from 2.23.3 to 3.0.0   \n",
      "9    61667  BUG: pd.read_sql is incorrectly reading long i...   \n",
      "10   61662  DOC: Improve documentation for DataFrame.__set...   \n",
      "11   61660  BUG: Type error supplying SQLAlchemy NVARCHAR ...   \n",
      "12   61659  BUG: to_numeric fails to convert a Pyarrow Dec...   \n",
      "13   61654          DOC: Add release notes template for 2.3.1   \n",
      "14   61653  [backport 2.3.x] CI: Fix slow mamba solver iss...   \n",
      "15   61651  feature #58141: Consistent naming conventions ...   \n",
      "16   61650  feature #49580: support new-style float_format...   \n",
      "17   61647  WEB: Moving maintainers to inactive (no answer...   \n",
      "18   61644  BUG: Add PyArrow datelike type support for `ma...   \n",
      "19   61643                          BUG: replace value failed   \n",
      "20   61642  ENH: Allow third-party packages to register IO...   \n",
      "21   61641  BUG: `to_numeric` fails to convert a Pyarrow D...   \n",
      "22   61640  BUG: Fix GroupBy aggregate coersion of outputs...   \n",
      "23   61637                            Fix void dtype handling   \n",
      "24   61636  BUG: Groupby aggregate coersion of outputs inc...   \n",
      "25   61635      Description of pandas_datetime_exec function.   \n",
      "26   61634             ENH: ExcelWriter append or create mode   \n",
      "27   61632  DOC: warn about apply with raw=True, if functi...   \n",
      "28   61631                                               DOC:   \n",
      "29   61629  BUG: to_stata erroring when encoded text and n...   \n",
      "\n",
      "                                               labels state  \n",
      "0                                                  []  open  \n",
      "1   [{'id': 76811, 'node_id': 'MDU6TGFiZWw3NjgxMQ=...  open  \n",
      "2   [{'id': 76811, 'node_id': 'MDU6TGFiZWw3NjgxMQ=...  open  \n",
      "3                                                  []  open  \n",
      "4                                                  []  open  \n",
      "5   [{'id': 76811, 'node_id': 'MDU6TGFiZWw3NjgxMQ=...  open  \n",
      "6                                                  []  open  \n",
      "7   [{'id': 76812, 'node_id': 'MDU6TGFiZWw3NjgxMg=...  open  \n",
      "8   [{'id': 129350, 'node_id': 'MDU6TGFiZWwxMjkzNT...  open  \n",
      "9   [{'id': 76811, 'node_id': 'MDU6TGFiZWw3NjgxMQ=...  open  \n",
      "10  [{'id': 134699, 'node_id': 'MDU6TGFiZWwxMzQ2OT...  open  \n",
      "11  [{'id': 76811, 'node_id': 'MDU6TGFiZWw3NjgxMQ=...  open  \n",
      "12                                                 []  open  \n",
      "13  [{'id': 134699, 'node_id': 'MDU6TGFiZWwxMzQ2OT...  open  \n",
      "14                                                 []  open  \n",
      "15                                                 []  open  \n",
      "16                                                 []  open  \n",
      "17  [{'id': 1508144531, 'node_id': 'MDU6TGFiZWwxNT...  open  \n",
      "18                                                 []  open  \n",
      "19  [{'id': 76811, 'node_id': 'MDU6TGFiZWw3NjgxMQ=...  open  \n",
      "20  [{'id': 2301354, 'node_id': 'MDU6TGFiZWwyMzAxM...  open  \n",
      "21  [{'id': 76811, 'node_id': 'MDU6TGFiZWw3NjgxMQ=...  open  \n",
      "22                                                 []  open  \n",
      "23                                                 []  open  \n",
      "24  [{'id': 76811, 'node_id': 'MDU6TGFiZWw3NjgxMQ=...  open  \n",
      "25                                                 []  open  \n",
      "26  [{'id': 76812, 'node_id': 'MDU6TGFiZWw3NjgxMg=...  open  \n",
      "27  [{'id': 134699, 'node_id': 'MDU6TGFiZWwxMzQ2OT...  open  \n",
      "28  [{'id': 134699, 'node_id': 'MDU6TGFiZWwxMzQ2OT...  open  \n",
      "29                                                 []  open  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "url = 'https://api.github.com/repos/pandas-dev/pandas/issues'\n",
    "resp = requests.get(url)\n",
    "\n",
    "print(resp)\n",
    "\n",
    "data = resp.json()\n",
    "print('\\n')\n",
    "print(data[0]['title'])\n",
    "\n",
    "issues = pd.DataFrame(data, columns=['number', 'title', 'labels', 'state'])\n",
    "print('\\n')\n",
    "print(issues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.4 Interacting with Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "\n",
    "query = \"\"\"\n",
    "    CREATE TABLE test\n",
    "    (a VARCHAR(20), b VARCHAR(20),\n",
    "    c REAL, d INTEGER\n",
    "    );\n",
    "\"\"\"\n",
    "\n",
    "con = sqlite3.connect('mydata.sqlite')\n",
    "con.execute(query)\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [('Atlanta', 'Georgia', 1.25, 6),\n",
    "        ('Tallahassee', 'Florida', 2.6, 3),\n",
    "        ('Sacramento', 'California', 1.7, 5)]\n",
    "\n",
    "stmt = \"INSERT INTO test VALUES(?, ?, ?, ?)\"\n",
    "con.executemany(stmt, data)\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Atlanta', 'Georgia', 1.25, 6), ('Tallahassee', 'Florida', 2.6, 3), ('Sacramento', 'California', 1.7, 5)]\n"
     ]
    }
   ],
   "source": [
    "cursor = con.execute('select * from test')\n",
    "rows = cursor.fetchall()\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('a', None, None, None, None, None, None), ('b', None, None, None, None, None, None), ('c', None, None, None, None, None, None), ('d', None, None, None, None, None, None))\n",
      "\n",
      "\n",
      "             a           b     c  d\n",
      "0      Atlanta     Georgia  1.25  6\n",
      "1  Tallahassee     Florida  2.60  3\n",
      "2   Sacramento  California  1.70  5\n"
     ]
    }
   ],
   "source": [
    "print(cursor.description)\n",
    "\n",
    "print('\\n')\n",
    "print(pd.DataFrame(rows, columns=[x[0] for x in cursor.description]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             a           b     c  d\n",
      "0      Atlanta     Georgia  1.25  6\n",
      "1  Tallahassee     Florida  2.60  3\n",
      "2   Sacramento  California  1.70  5\n"
     ]
    }
   ],
   "source": [
    "import sqlalchemy as sqla\n",
    "\n",
    "\n",
    "db = sqla.create_engine('sqlite:///mydata.sqlite')\n",
    "print(pd.read_sql('select * from test', db))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
